# -*- coding: utf-8 -*-
"""NLP_Review_G/B

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PfQ0L9f3fSZFR5aRMA_1lGCeBlLYPPHT

## Importing the libraries
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

"""## Importing the dataset"""

dataset = pd.read_csv('Restaurant_Reviews.tsv', delimiter = '\t', quoting = 3)

"""## Cleaning the texts

In this we're removing punctuations, and changing words to verb (root)(stemming )and replacing uppercase to lowercase These are not required for the model to know
"""

import re # to clean data
import nltk #nlp toolkit library
nltk.download('stopwords')
from nltk.corpus import stopwords 
from nltk.stem.porter import PorterStemmer
corpus = []
for i in range(0, 1000):
  review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])
  review = review.lower()
  review = review.split()
  ps = PorterStemmer()
  all_stopwords = stopwords.words('english')
  all_stopwords.remove('not')
  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]
  review = ' '.join(review)
  corpus.append(review)

print(corpus)

"""##  Bag of Words model

basic algorithm for the nlp
"""

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features = 1500)
X = cv.fit_transform(corpus).toarray()
y = dataset.iloc[:, -1].values

"""##  dataset splitting"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

"""Naive Bayes training"""

from sklearn.naive_bayes import GaussianNB
classifier = GaussianNB()
classifier.fit(X_train, y_train)

"""Multinomial Naive Bayes"""

from sklearn.naive_bayes import MultinomialNB
mclassifier = MultinomialNB()
mclassifier.fit(X_train, y_train)

"""Random forest classifier"""

from sklearn.ensemble import RandomForestClassifier 
  
# n_estimators can be said as number of 
# trees, experiment with n_estimators 

model = RandomForestClassifier(n_estimators = 501, 
                            criterion = 'entropy') 
                              
model.fit(X_train, y_train)

"""## Predicting the Test set results"""

y_pred_gb = classifier.predict(X_test)
print(y_pred_gb)           #gaussian naive bayes

y_pred_rf = model.predict(X_test)
print(y_pred_rf)           #random forest

y_pred_mb =mclassifier.predict(X_test)
print(y_pred_mb)           #multinomial naive bayes

"""## Confusion Matrix"""

from sklearn.metrics import confusion_matrix, accuracy_score,precision_score,recall_score
cm = confusion_matrix(y_test, y_pred_gb)
print(cm)
accuracy_score(y_test, y_pred_gb)

cm = confusion_matrix(y_test, y_pred_rf)
print(cm)
accuracy_score(y_test, y_pred_rf)

cm = confusion_matrix(y_test, y_pred_mb)
print(cm)

score1 = accuracy_score(y_test,y_pred_gb)
score2 = precision_score(y_test,y_pred_gb)
score3= recall_score(y_test,y_pred_gb)
print("Gaussian NaiveBayes")
print("\n")
print("Accuracy is ",round(score1*100,2),"%")
print("Precision is ",round(score2,2))
print("Recall is ",round(score3,2))

score1 = accuracy_score(y_test,y_pred_rf)
score2 = precision_score(y_test,y_pred_rf)
score3= recall_score(y_test,y_pred_rf)
print("Random forest Classifier")
print("\n")
print("Accuracy is ",round(score1*100,2),"%")
print("Precision is ",round(score2,2))
print("Recall is ",round(score3,2))

score1 = accuracy_score(y_test,y_pred_mb)
score2 = precision_score(y_test,y_pred_mb)
score3= recall_score(y_test,y_pred_mb)
print("Multinomial NaiveBayes")
print("\n")
print("Accuracy is ",round(score1*100,2),"%")
print("Precision is ",round(score2,2))
print("Recall is ",round(score3,2))

"""Now to predict for a single review , is positive or negative

### Positive review
We are giving our own statement for the model.Just to see how the output looks like. As of now , we took multinomial bayes as our trained model..
"""

new_review = ' love the crust'
new_review = re.sub('[^a-zA-Z]', ' ', new_review)
new_review = new_review.lower()
new_review = new_review.split()
ps = PorterStemmer()
all_stopwords = stopwords.words('english')
all_stopwords.remove('not')
new_review = [ps.stem(word) for word in new_review if not word in set(all_stopwords)]
new_review = ' '.join(new_review)
new_corpus = [new_review]
new_X_test = cv.transform(new_corpus).toarray()
new_y_pred = mclassifier.predict(new_X_test)
print(new_y_pred)

"""This review is predcited as 1 for positive by the model.

### Negative review
"""

new_review = 'I hate this restaurant so much'
new_review = re.sub('[^a-zA-Z]', ' ', new_review)
new_review = new_review.lower()
new_review = new_review.split()
ps = PorterStemmer()
all_stopwords = stopwords.words('english')
all_stopwords.remove('not')
new_review = [ps.stem(word) for word in new_review if not word in set(all_stopwords)]
new_review = ' '.join(new_review)
new_corpus = [new_review]
new_X_test = cv.transform(new_corpus).toarray()
new_y_pred = mclassifier.predict(new_X_test)
print(new_y_pred)

"""The review was correctly predicted as negative by our model."""

